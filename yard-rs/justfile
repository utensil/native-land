set fallback

example_xp := justfile_directory() / "example-xp"

# export MAMBA_ROOT_PREFIX := clean(join(justfile_directory(), ".." , ".." ,  "micromamba"))
# mm_packages := join(MAMBA_ROOT_PREFIX, "envs", "tch-rs", "lib", "python3.11", "site-packages")
# export LIBTORCH := if os() == "windows" { "" } else { join(mm_packages , "torch") }

LIBTORCH_PREFIX := clean(join(justfile_directory() , ".." , ".."))
export LIBTORCH := join(LIBTORCH_PREFIX, "libtorch")
 
env_sep := if os() == "windows" { ";" } else { ":" }
export PATH := join(LIBTORCH, "lib") + env_sep + env_var("PATH")
export LIBTORCH_BYPASS_VERSION_CHECK := "1"
export DYLD_LIBRARY_PATH := join(LIBTORCH, "lib")
export DYLD_FALLBACK_LIBRARY_PATH := join(LIBTORCH, "lib")
# + env_sep + env_var_or_default("DYLD_LIBRARY_PATH", "")

default:
    just list

check:
    just
    echo "LIBTORCH=$LIBTORCH"
    echo "PATH=$PATH"
    echo "DYLD_LIBRARY_PATH={{DYLD_LIBRARY_PATH}}"

[group('dx')]
prep-dx:
    cargo install dioxus-cli
    @echo "create a new project: dx new"

[group('dx')]
dx-new:
    dx new

[group('dx'), no-cd]
dx-css:
    bunx tailwindcss -i ./input.css -o ./assets/tailwind.css --watch

[group('dx'), no-cd]
dx-dev:
    dx serve --hot-reload --platform desktop

[group('dx'), no-cd]
dx-test: dx-prep-test
    just test

[group('dx'), no-cd]
dx-cov: dx-prep-test
    just cov

[group('dx'), no-cd]
dx-prep-test:
    cargo add dioxus-ssr pretty_assertions futures

[group('cl'), no-cd]
cl-run:
    clear
    cargo run --example gelu --features wgpu

[group('tracy'), no-cd, macos]
prep-tr:
    brew install tracy

[group('tracy'), no-cd]
tr-bevy:
    @echo "open another terminal and run: cd {{invocation_directory()}}; cargo run --features bevy/trace_tracy"
    tracy-capture -f -o my_capture.tracy
    @eacho "run: tracy my_capture.tracy"

[group('tracy'), no-cd]
tr-bevy-live:
    tracy -a 127.0.0.1 -p 8086 &
    RUST_LOG=info cargo run --features bevy/trace_tracy

[group('tracy'), no-cd]
tbl: tr-bevy-live

# not working
[group('tracy'), no-cd, private]
ct-bevy:
    cargo run --release --features bevy/trace_chrome

# https://doc.rust-lang.org/nightly/cargo/reference/timings.html
[group('tracy'), no-cd]
bt *PARAMS:
    cargo build --timings {{PARAMS}}

[group('ex')]
@prep-ex URL DIR BRANCH:
    #!/usr/bin/env bash
    mkdir -p {{example_xp}}
    cd {{example_xp}}
    if [[ ! -d {{example_xp / DIR}} ]]; then
        git clone --depth=100 {{URL}} {{example_xp / DIR}}
    fi
    cd {{example_xp / DIR}}
    git checkout {{BRANCH}}

# breakout scene_viewer
# storage_buffer gpu_readback
# low_power monitor_info screenshot transparent_window
# 3d_viewport_to_world anisotropy camera_sub_view depth_of_field fog_volumes lightmaps
# motion_blur pbr post_processing query_gltf_primitives reflection_probes render_to_texture
# split_screen spotlight ssr tonemapping transmission two_passes volumetric_fog 
# Not enough memory left: meshlet pbr_multi_layer_material_textures
# custom_post_processing extended_material gpu_readback shader_prepass storage_buffer fps_overlay hot_asset_reloading asset_processing
# headless_renderer
# not working: loading_screen

[group('ex')]
try-bevy +PARAMS: (prep-ex "https://github.com/bevyengine/bevy" "bevy" "main")
    cd {{example_xp / "bevy"}} && cargo run --features="jpeg pbr_anisotropy_texture bevy_dev_tools file_watcher" --release --example {{PARAMS}}

[group('ex')]
gltf:
    just try-bevy scene_viewer {{ example_xp / "black_hole" / "scene.gltf" }}

[group('ex')]
try-compute +PARAMS: (prep-ex "https://github.com/AnthonyTornetta/bevy_easy_compute" "compute" "main")
    cd {{example_xp / "compute"}} && cargo run --release --example {{PARAMS}}

# shaders/compute-shader runners/wgpu multibuilder 
# not working: 
# - runners/ash : path error
# use release to bypass https://github.com/Rust-GPU/rust-gpu/issues/29
[group('ex')]
try-rg EX="runners/wgpu": (prep-ex "https://github.com/Rust-GPU/rust-gpu" "rust-gpu" "main")
    cd {{example_xp / "rust-gpu" / "examples" / EX }} && cargo run --release

# need to manually uncomment the features in Cargo.toml
# and separately open: tracy -a 127.0.0.1 -p 8086
# unfortunately, it seems to only trace CPU, not GPU
[group('ex')]
try-wg : (prep-ex "https://github.com/gfx-rs/wgpu" "wgpu" "trunk")
    cd {{example_xp / "wgpu" }} && cargo bench -p wgpu-benchmark --features tracy

# need to change the version of tracy-client to match the tracy installed, see https://github.com/nagisa/rust_tracy_client
# but still only CPU usage
# press space generates a trace.json to view on https://ui.perfetto.dev/ but little info on GPU
[group('ex')]
try-wp: (prep-ex "https://github.com/Wumpf/wgpu-profiler" "wgpu-profiler" "main")
    cd {{example_xp / "wgpu-profiler" }} && cargo run --example demo

# fusing normalization sum_things
[group('ex')]
try-cl EX="gelu": (prep-ex "https://github.com/tracel-ai/cubecl" "cubecl" "main")
    cd {{example_xp / "cubecl" }} && cargo run --release --example {{EX}}

# run just prep-tch before running the tch examples!!

# basics 

[group('ex')]
[macos]
try-tch EX: (prep-ex "https://github.com/LaurentMazare/tch-rs" "tch-rs" "main") prep-tch-data
    #!/usr/bin/env bash
    cd {{example_xp / "tch-rs" }}
    if [[ {{EX}} == "char-rnn" ]]; then
        # replace Device::cuda_if_available() in examples/char-rnn/main.rs to Device::Mps
        sed -i '' 's/Device::cuda_if_available()/Device::Mps/g' examples/char-rnn/main.rs
    fi
    DYLD_FALLBACK_LIBRARY_PATH={{DYLD_FALLBACK_LIBRARY_PATH}} cargo run --release --example {{EX}}

prep-tch-data:
    #!/usr/bin/env bash
    set -e
    mkdir -p {{example_xp / "tch-rs" / "data"}}
    cd {{example_xp / "tch-rs" / "data"}}
    # for char-rnn
    if [[ ! -f {{"input.txt"}} ]]; then
        curl https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -o input.txt
    fi
    if [[ ! -f {{"train-images-idx3-ubyte"}} ]]; then
        curl https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz -o train-images-idx3-ubyte.gz
        yes|gunzip train-images-idx3-ubyte.gz
    fi
    if [[ ! -f {{"train-labels-idx1-ubyte"}} ]]; then
        curl https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz -o train-labels-idx1-ubyte.gz
        yes|gunzip train-labels-idx1-ubyte.gz
    fi
    if [[ ! -f {{"t10k-images-idx3-ubyte"}} ]]; then
        curl https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz -o t10k-images-idx3-ubyte.gz
        yes|gunzip t10k-images-idx3-ubyte.gz
    fi
    if [[ ! -f {{"t10k-labels-idx1-ubyte"}} ]]; then
        curl https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz -o t10k-labels-idx1-ubyte.gz
        yes|gunzip t10k-labels-idx1-ubyte.gz
    fi

[group('ex')]
rm-ex NAME:
    rm -rf {{example_xp / NAME}}

[group('ex')]
mp:
    just try-compute multi_pass

# [macos]
# prep-vk:
#     brew install molten-vk


# following https://github.com/ssoudan/tch-m1

LIBTORCH_FILENAME := if os() == "windows" {
    "libtorch-win-shared-with-deps-2.4.0%2Bcpu.zip"
} else if os() == "linux" {
    "libtorch-cxx11-abi-shared-with-deps-2.4.0%2Bcpu.zip"
} else if os() == "macos" {
    if arch() == "aarch64" {
        "libtorch-macos-arm64-2.4.0.zip"
    } else {
        "libtorch-macos-arm64-2.4.0.zip"
    }
} else {
    ""
}

LIBTORCH_ZIP_PATH := clean(join(LIBTORCH_PREFIX, LIBTORCH_FILENAME))
LIBTORCH_DIR := clean(join(LIBTORCH_PREFIX, "libtorch"))
    
[group('tch')]
prep-tch:
    #!/usr/bin/env bash
    # $HOME/.local/bin/micromamba env create -y -f tch-xp/environment.yml
    if [[ ! -f {{ LIBTORCH_PREFIX / LIBTORCH_FILENAME }} ]]; then
        curl {{ "https://download.pytorch.org/libtorch/cpu" / LIBTORCH_FILENAME }} -o "{{ LIBTORCH_ZIP_PATH }}"
    fi
    echo "Downloaded to {{ LIBTORCH_ZIP_PATH }}"
    if [[ ! -d {{ LIBTORCH_DIR }} ]]; then
        unzip -o "{{ LIBTORCH_ZIP_PATH }}" -d "{{ LIBTORCH_PREFIX }}"
    fi
    echo "Unzipped to {{ LIBTORCH_DIR }}"


