<!-- livebook:{"persist_outputs":true} -->

# Nx

```elixir
Mix.install([
  {:nx, "~> 0.9"},
  {:exla, "~> 0.9"},
  {:emlx, github: "elixir-nx/emlx", branch: "main"}
])
```

## Getting started with Nx

```elixir
Nx.default_backend({EMLX.Backend, device: :gpu})
```

<!-- livebook:{"output":true} -->

```
{Nx.BinaryBackend, []}
```

```elixir
Nx.Defn.default_options(compiler: EMLX)
```

<!-- livebook:{"output":true} -->

```
[]
```

```elixir
 t = Nx.tensor([[1, 2], [3, 4]])
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s32[2][2]
  EMLX.Backend<gpu, 0.872558687.1883111428.141904>
  [
    [1, 2],
    [3, 4]
  ]
>
```

```elixir
Nx.shape(t)
```

<!-- livebook:{"output":true} -->

```
{2, 2}
```

```elixir
Nx.divide(Nx.exp(t), Nx.sum(Nx.exp(t)))
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][2]
  EMLX.Backend<gpu, 0.872558687.1883111428.141921>
  [
    [0.032058604061603546, 0.08714432269334793],
    [0.23688285052776337, 0.6439142227172852]
  ]
>
```

```elixir
defmodule MyModule do
  import Nx.Defn

  defn softmax(t) do
    Nx.exp(t) / Nx.sum(Nx.exp(t))
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, MyModule, <<70, 79, 82, 49, 0, 0, 9, ...>>, true}
```

```elixir
MyModule.softmax(Nx.tensor([1, 2, 3]))
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[3]
  EMLX.Backend<gpu, 0.872558687.1883111444.139536>
  [0.09003056585788727, 0.2447284609079361, 0.665241003036499]
>
```

```elixir
will_jit = EXLA.jit(&MyModule.softmax/1)
will_jit.(t)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][2]
  EXLA.Backend<host:0, 0.872558687.1883111444.139537>
  [
    [0.032058604061603546, 0.08714432269334793],
    [0.23688282072544098, 0.6439142227172852]
  ]
>
```
